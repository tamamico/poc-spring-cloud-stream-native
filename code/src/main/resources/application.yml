logging:
  level:
    root: info
    org.apache: warn
    io.confluent: warn

spring:
  application:
    name: poc
  cloud:
    stream:
      bindings:
        greet-in-0:
          group: ${spring.application.name}
          destination: ^input\.(?:men|women)\.avro$
          consumer:
            use-native-decoding: true
        greet-out-0:
          destination: output.avro
          producer:
            use-native-encoding: true
      kafka:
        binder:
          auto-create-topics: false
          consumer-properties:
            basic.auth.credentials.source: USER_INFO
            basic.auth.user.info: ${kafka.user}:${kafka.password}
            key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
            value.deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
            specific.avro.reader: true
          producer-properties:
            basic.auth.credentials.source: USER_INFO
            basic.auth.user.info: ${kafka.user}:${kafka.password}
            key.serializer: org.apache.kafka.common.serialization.StringSerializer
            value.serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
          configuration:
            metadata.max.age.ms: 10000
            security.protocol: SASL_SSL
            sasl.mechanism: PLAIN
            sasl.jaas.config: >
              ${kafka.login.module:org.apache.kafka.common.security.plain.PlainLoginModule}
              required username='${kafka.user}' password='${kafka.password}';
            value.subject.name.strategy: io.confluent.kafka.serializers.subject.RecordNameStrategy
        bindings:
          greet-in-0:
            consumer:
              destination-is-pattern: true
              reactive-auto-commit: true
              standard-headers: both
